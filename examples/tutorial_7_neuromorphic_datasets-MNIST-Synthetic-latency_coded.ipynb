{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec239839",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_7_neuromorphic_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5313e-c29d-4581-a9c7-a45122337069",
   "metadata": {
    "id": "47d5313e-c29d-4581-a9c7-a45122337069"
   },
   "source": [
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"300\">](https://github.com/jeshraghian/snntorch/) \n",
    "[<img src='https://github.com/neuromorphs/tonic/blob/develop/docs/_static/tonic-logo-white.png?raw=true' width=\"200\">](https://github.com/neuromorphs/tonic/)\n",
    "\n",
    "\n",
    "# Neuromorphic Datasets with Tonic + snnTorch\n",
    "## Tutorial 7\n",
    "### By Gregor Lenz (https://lenzgregor.com) and Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/examples/tutorial_7_neuromorphic_datasets.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oll2NNFeG1NG",
   "metadata": {
    "id": "oll2NNFeG1NG"
   },
   "source": [
    "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
    "\n",
    "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". arXiv preprint arXiv:2109.12894, September 2021.](https://arxiv.org/abs/2109.12894) </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ClgsZMOfBVby",
   "metadata": {
    "id": "ClgsZMOfBVby"
   },
   "source": [
    "# Introduction\n",
    "In this tutorial, you will:\n",
    "* Learn how to load neuromorphic datasets using [Tonic](https://github.com/neuromorphs/tonic)\n",
    "* Make use of caching to speed up dataloading\n",
    "* Train a CSNN with the [Neuromorphic-MNIST](https://tonic.readthedocs.io/en/latest/datasets.html#n-mnist) Dataset\n",
    "\n",
    "If running in Google Colab:\n",
    "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\n",
    "* Next, install the latest PyPi distribution of snnTorch and Tonic by clicking into the following cell and pressing `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hDnIEHOKB8LD",
   "metadata": {
    "id": "hDnIEHOKB8LD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tonic --quiet \n",
    "!pip install snntorch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e14b2",
   "metadata": {},
   "source": [
    "## making the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5b69da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Training Parameters\n",
    "batch_size=128\n",
    "data_path='/data/mnist'\n",
    "num_classes = 10  # MNIST has 10 output classes\n",
    "num_steps = 100\n",
    "\n",
    "# Torch Variables\n",
    "dtype = torch.float\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((34,34)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f4a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 128, 1, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "from snntorch import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# Iterate through minibatches\n",
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data\n",
    "spike_data = spikegen.latency(data_it, num_steps=num_steps, tau=5, threshold=0.8, clip=True, normalize=True, linear=True)\n",
    "\n",
    "print(spike_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c673cd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAeN21kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAOQZYiE\n",
       "ADv//vdOvwKbRZdqA5JXCvbKpCZZuVJrAfKmAAADAAARsG58lw15q9IkAACtobhz+EtXgAGbPfnA\n",
       "6vBq2y4KD1VFSYr8QiGU1RZ6il6SV2xj+fxPL8Qg2QVIKh1DFq4qvaj95v4WsMdmfuuUAqmGmgt7\n",
       "2qfAnam+BtJ+fYoQA9tZoWlRr83hsPbYsyMd8RAo29/moVhmYMXfXEyzuZIIwEM5t7qaBcoqc6Kt\n",
       "xsaD4gGY5Rti9o006m8mCY8zFajtUJj2GMkzWnxEudEkG3nu2ZJCf2QhSgfeKj1z4XSl/L/saVK8\n",
       "rJgaM8L7I+TZrEBnlLH+V13/wDsTnV3sqyGEcP5S9uqf7Byf7JDc7DlndfE9iz9CgNGajW0zVWIE\n",
       "G1TPv1p0xU3WJLcDogG3aRsyKpGBV7c/tt20xUJEQsVAsestKptbii52dG39vreSjWVmY1HoSIjX\n",
       "mbBCbtKnYjX5QtspK+jqtsL6LAw9YM0j9a9ArjV+eC/XrKIri3Re6toFFj2ajsVA+LSOMUcMziXz\n",
       "Ohg1t8FX1GyQaG5hyLuFZLxGy/PiLRZZ+6Cz//+PSB8bI0NvNOiMoT4RL8cAsLiNssDSYcnwDYiJ\n",
       "oCY3TzZuj9Ocgr0aWtZWIGmIUin2nwpJp7j8P+Kxe9X89ikPye8hWe5l8xbtEjVt94Ol/zbnJ7s+\n",
       "HVOc6WPWl7bfbl/LyG8r950xL8JwdD1lg5u9q3uGRCkC/9HoTCo6Bok7e4KzBnAKNwivqG6vgoA5\n",
       "RGu4B7PQlHBTIJLyiKSP698mBpPN+DxkoZEUbbLkZryeGakVLyPlVbxHnamHSjgqQwnfWO+0Zcu+\n",
       "Gk+Rj/gWkjsZDuMXGdm79P5zXdopTqKMibJgs3v66HsegeUHLeC1jp8r0H/Fdp0gdbDHimQbqEew\n",
       "epi70lMkijGdqksktE82GlnaGsGDvc4Wvl4VryAVSKZV74JqfZNfGSGRd2/TyGFlQ1YL1gChgLp/\n",
       "Rv4qc6yxSHkWM/dntJMKkqw+iVG3djG7ThzRHZfz4OSUCKTKnlZbGARtdOcw+EslpDHTPdM7uKE6\n",
       "5NALcFzMx93uGPn23aqyUB7C3nKlOfiZ8q2a44snGo8Y958W4yFzjLNZv/4wIUCCwEIEf7x5kUeH\n",
       "qsw/S7G43eiVINtWN/IBtgzIfv5kPT+RRGPDe4fo+YNzsBiArQeGhLhGepmDlw0AACVLvoOPAAAB\n",
       "80GaI2xDv/6plgCQMI9ACHcOmugDc9A8v6KPE944AgnvTobK338b72RGb+dZEj/aUmhq2uwhaOQg\n",
       "iH9pqEcyKd56DSZd5hJu007S6VjUSVtwm8w8bswxQ/QZ/PgaeB5qm5BOHbwN6g8RkkxnyloxgJB6\n",
       "wzk944keVMda/YUPGUHf2sSeu7wbftLVvl4wpJ6C0e7KH2Fzq3///xlsNHLjx3E2kWpQ7Vyanuts\n",
       "8AU4Iw/LRMLrI6O6zqBZUfgcM+Pxx1w2Dz6jxRQe/PhMNE7WQrc+m5nDNKr+oUPuEcvGT4zkNvYf\n",
       "K0SNzdqkrYcs1fmC6hSR/FK85YPAwh1MtECgOwSsbwP8qcWEOu6ghe4awE+LJ+xAD5n94CT+a8Hd\n",
       "Od4xFhbgFFIKsX7zbiDRWc7sVcy9NW3nevnEUffkKlszSZ/+sbMmQHbYqt8jePoDjoEHJv8PAxoo\n",
       "zKncVTYN1zqrXO7yBjG9Nf8knnGcq24mzcXFK/g9CjQ0IEWQY2IAmQej8F9PB3o/lSKpN6C40c4J\n",
       "iet3xuCdyBzGbRfndUQhoDNCKVpTS4BVlnTXVUFfeMQV6nyYDBG4OxtgshJCP/HvzVMSLxnvAF4s\n",
       "YAbb5jSDlGyRx4yKc/BnS48FEdMdZPituv9eToT7w2TCcwTzK7yriellPuwAAAF0QZ5BeIV/AOeB\n",
       "uStqXBnXB+wBXgBO3mKnMNJqyQzEL+1d37EPc2kXPVQ/bvjrmRDBlpWpQVewTObdxOyPICf1ER3o\n",
       "iMP7QPknE0siYIU8TTFG/mOuyUL2vfbTq4dWskmkOvPwy93P4bOgaOC9fnmf/wiE1m6+R++YpQlH\n",
       "AQtpKgTwhS0LLPTYwXXnfI4BXezono+yXD2DHbiKH7bjP9rXlh3UnqcynrVO8SBToSKZRMkjgdO5\n",
       "bNk6ytQZde2u2wyHsFR1O8kA9qKYh8fsZBHZJRJZ/w8qJe0bejOGerVnas51UnfWBYLXQCGgz3bO\n",
       "V+wt1rswKkYmmrucH3vz4ehL/U/5dLCSgaYt1Mg6EGt0fNz+dgOQUW5rbbyLkkKjSRYgLRhGNsf9\n",
       "wl/zwRN3+3CE3OSr4tLYe406Vbx+X65peQoN58Ow8W73twTZDgWck0JbRRkgrSg3T+a4idB3T33m\n",
       "qOwOYZFN8iahbgw2RvNr8d0T5BWBAAAAvwGeYmpCvwAhuuk4ivTYgBGR1X1ZfAFgs6fZe449Ea3T\n",
       "8uA6G9Mgp0DFA7Yuxy8conMjwAYQvtwzIFd3bYEQfKQ8n0/XlsoZlZs8ObmEoy1rTq0e7jJVX9fR\n",
       "H4jPuatjQdx7QTK80/LdQYc5V32edpoU2ckzKNKHhnbzQ6CvAWm6pM2Dzyzh0JEyUU70ootxBtQo\n",
       "h8jD2XwkMa4Q5LBfC8GZ9GNqnpde9z6QTpJxEmT187KGpf7zWIVsQn1h20RXAAAAtUGaZ0moQWiZ\n",
       "TAh3//6plgAVT4BxqX/VwNDJmtq28pGENNCagMqpI566fpHLyDP4fkQ2ksKjBJcgAeGACHj5S19T\n",
       "zMrt/PvpSImg8Xi48wtRyUfBlPJYiti4YZk8lPGXGa5aqi2YRENpaJBt+bzdv0dCGTm5lPgOjgrP\n",
       "pOM2t576sy7mVunHNOrDdZknns2+P+fbhV0B7VYPWv72/O02r4CT+dVreoPW2bpi4y2lP6eVj9h8\n",
       "fs0AAAD4QZ6FRREsL/8AGSDkEdygg8B7/AAy7Ni+tGykyOiNG9+f72LCGQ3J1bt83ZfBridSO0Q/\n",
       "2xSP9IY9vAyQu5jHPGX4ECiDTlAJ+1y+17EddMA3ySjuUpiodtFowRKNS8IDbL5ay7dz3jgDxIGE\n",
       "ZnnoXu+b0m+TA271wf6fz9US2qX2CS0oRX335Sdxv780FOPDLbWALaG5ivzAfpZHoaVvVNQvekjP\n",
       "LyMeu74nfNgvzBlh/H/Bc75uJua0jXGyhiIkblkBBVKd3VXmG8K1LNL/iMwAjyZRU9b9D6+CAVCu\n",
       "PQrPwtbDJOGgrk4A3x0L8iLHcB1KBgNj+IEAAACLAZ6kdEK/ACLB9wtX6LsJYmc7sAHmFs0O/oXf\n",
       "PISXySaLYBcg1J9Y9OP3HQ4QNmOhCbhl2pSaag0GIXFvdgCF6fSse/IEuLlWwUNnGTM1t/Mfo2Pj\n",
       "QTRM/LjOXxzcoQtR0UnvWl+H6hp8yA8OgjuWzS59MC87rNEd9j5AqDP//v4NJTdyo3ZrPF9M4QAA\n",
       "AO4BnqZqQr8AIVKvgZkyYAP216fSkfGKJ/O2iQPVnw+qtPrhl1vwsbv3RyMtNRCNyzml3kiPMZ0H\n",
       "EK6LgRU2ngMfxA48RX/O0YQvf2koIuQ1/Le3rQK0aOCXcGMlj8TrBlx3WIcZWSdoifhr2voNaugv\n",
       "bzVw2KW7S37WMup0is5MVMYE42B3ynwiDEWHUH/wMXKJWjiNGMkRxbn1VaVrYVsAVmPRVnruisot\n",
       "N6KLa7HJYB5MtndVeenzDaG5EiOafpIWyL1lb4dlpfvkyqdcxgALRyO+ha0kX0ETOwyCUswDBdUY\n",
       "eIQtHanM2kvzkBk5AAABFEGaqkmoQWyZTAh3//6plgAVwJ10VtsQAZaeIfbkfE73dWRVOmkyR304\n",
       "fBdSzoAumDn2QUh+Bds2yKN0PgBG2dSX8A1LKjDvG0HjPMTDsCmvzXmS+qeNGnu2d4LQeEml/Hh7\n",
       "CkKKDrU+RLCZb5yN7MDJI6XMXlrrW5XdAWElN+6HtveS6U4tsBsQA2v+xHgPWa2A1EA+xbLq3SlP\n",
       "0I0WAu0mVGkLBNW63UEDrm3jNrWtuWLKE6WcD5YsEX/wq2N1Ot9W2xE5S64Y9nfTdOnRySJ2ILeL\n",
       "0+6ixWdEa/xFTyI8PYuYQKtQj8O/XpeOuxtfe0fLorZGVikoMVAhD8ztBhow4QbCcT+GofltzvDH\n",
       "6KMzNQge+AAAAMRBnshFFSwr/wASXYr7zTcNiWjoQCltDwjCvABfWL08RKWiz6iH5WPx/lrFYZie\n",
       "3HgPSk4j4DSmyqrYt6L075jHPkoc9eNVdYgj2hxQhgc6LC0YWchdJAinqhqrHN2FRfOOJEIpjB33\n",
       "vzNeXIfJze1bBzzjOhNCXpTAA5MokqWGDO4Qm21NrBCZCODiAaOl3s9hud6suo/8Hg/Q9yKDz1Ao\n",
       "+9X/FnQTUjdhJFj5app8xO60rmaBIHADi04hbEW958TR1aCwAAABqAGe6WpCvwASV3/7Pyo+hEZT\n",
       "+vB5Ne/oAQLQlZ0gBvbazS5a3muE0udsyf9DhAtlAqRlbpggbsZs90sQtJ6DXvSa0mjpSEa0yU6x\n",
       "09YPcPJXVuNBYRxYca57UmoDSr1LkHPZNndtsiLGwvskEH0OXPQBX5+whR3xDP9AFbLKosPD/pFF\n",
       "Qsmhu+/srmBx0jlJ+2wBMC9/Nth+eTPRVcjn/sa5Shacnw0ix9v8L7APYWJxSmxGOF+yY48I8s50\n",
       "37ackp8A/xERORroeXi+qjCpD97pXsBdiXU2jVPnVNAPLmhkauyB8zA2blZ1Qcm99X3B6D5zWhKD\n",
       "N0OtNv8m8FYPSxAij7pGk408jFfQ1UUiYPaPN/WFjnaRU+PO2nJQLzw4rzgaWPGVkNba37xwnROl\n",
       "5Pdguq5FaCem1MozUsP2yBevhQH2vMfCMvnAbDzXjanNswfN6Hec9EnaMNqymC3DdBVj8Hlexvz/\n",
       "Lzu3jlPIb7dotQiso3ddwvRhpAgPFUr8dFsfZeGSJMByMOLiycZz/5Atkx1jYS6BFDkJblFsM1vb\n",
       "fHK9YJiyzYEAAADiQZruSahBbJlMCHf//qmWAAt/wDtiTmQYNaZyRl+WYAIevjFr6C550hLdjDDR\n",
       "uleWrwSaERpJURa0u52qeHVyAQTn+6zUlJzq8ri01ueLxsEPToIiWtT+TdNFHpJiA316S/0PpxaH\n",
       "y3tl8pxjC2A66hSUIvW9sAX4u3D5DjNUj8aj4L2YOWzkW0Z2vW3znuCJa+TdvSUVnReGBTCEMuxG\n",
       "i9bTlQsaILjUSif963FsU1oe15+iYfvkt3YLOs7GUvFYmEdqMDynrHWu87da+iT6wk15MK+mCHJD\n",
       "VfwevlD1Vl7crAAAAMBBnwxFFSwv/wANgE6C+Cb5gACWTChMj1S0TDPuTcqx7z0VmAwPyN32D/KQ\n",
       "JbVklMLe4qAc+PXQR5HGPbEqaz8Ziia8vNI8CTRK4HxdSfxJgpbb/9yoC44mPO5V6cCIPflpXTGu\n",
       "dbRppvMIlOPBXGaoHq4Sqe0As2JNqbY0ELlLgKejwSSzUYaf3//4cbH7jyzNTn1UBHQonSxtjK01\n",
       "8EosQIYUbeUJ4eFcDFbXnfQ6TtGNQt0rBnFoeODKUZKsbwgAAAD5AZ8rdEK/ACBSr4t7iV8AGz5M\n",
       "fNSLSuO27Lwgb/2vdj2amUf29RDoSYTba56k022PBUSkj5LtSiGeUxfqyfJfMS6C3mil5XtQB7fB\n",
       "HT1l9nYofrvocTVoneng5tQmV+K6g25gg4gIH9B/RCFY9wPJPs75WiWEYntS3F2BxmmVr9/YUR0X\n",
       "hEzUqmS5s8MyGj/YVxzUU8Vz7FweGggpLTmN6V5K1x0rkXAFZXC3zY+5cKbM3NFrLUXCOZ/WZn5q\n",
       "d2GuGhtzBUPjq6ezOMsXfhZ3Vyw21xEZxu35dGLzrmYCfMwCW80CTv3We4NYQAMYWmC484eWSOi0\n",
       "6+0xAAAApwGfLWpCvwAfGvVCrLA+gYach3isN8fHZcDNX7AA4s+StHmOEXPILkOToMgp4HgFCGjm\n",
       "NgkHjtV+ZJTC3uJrlc7yWDoXzlHP/L6WLwNXn8L1Ykibpa32xTpunlMfL0vUGTxYmS9Q/PaBSe2s\n",
       "ke78i41fyGCeZDGQ0R823ZDijqcSTlQyEYGZSPQAwX0PzFtF61JXLqNUbPvDZF3M2Xaxa4PQAPdc\n",
       "D6mBAAAAJEGbMkmoQWyZTAh3//6plgAKF8A2oKzZugFdSORos69vY41RbQAAAMNBn1BFFSwv/wAY\n",
       "QpfjJuW7wAOxli+tGHeAUtoiU3apGEwCaCbG28IP39b/8Cz4JkbOdRD4mdDZEmmCH//4ciSN/fSq\n",
       "NaQdCIEaC18x6Vf9aoGkisqickQXbDCLkuDwsOwQB77KYszQo6ae15bOagVicBZDoEfUFVPqTM/7\n",
       "5r2LOyeF8PeLLni7tw4BCaNfPsEocXd9WeaPnyrXf5mLEkYF2kX70DLKyxaWMBdPFgkXaTH68Hyz\n",
       "6mMRBmhVn0h7q+h9wtwAAABBAZ9vdEK/ACC+C+yAJ8t7auFubNGqMpNBESPiUwAdkXQUhn7LCZbt\n",
       "aQfLOVXyYQJc7ZzMNfvGWWQcfaWep12/3JwAAACPAZ9xakK/ACCyExUgFHRv64JnV+oAXT5KfaEf\n",
       "ECeqe1JI/l0dc+YGy24srkwIy4t5+2Hdg2ctvTpae5N+zeoU7b8EHBEjcwo9xutoxiOB9CzSxjuZ\n",
       "WJA3xXjeoN0lvkomdGn0zybDVY31eNCK6afTt+XY52ChM1HZFDhes7xly0hiHdVnohqoAHipO1hw\n",
       "L4EAAAAVQZt2SahBbJlMCHf//qmWAAADAPCAAAAAUUGflEUVLC//AAF+iMVvjyklBf3J2X4afhQo\n",
       "AIg8KYwpFoZaOFITd7FxPaxVdgK5a3jVCueyCe85mZo5g9hszthhBOKlWC/uF4HIQB1lyc2twAAA\n",
       "ALkBn7N0Qr8AINAegA2hf/+HGh3PKMr/23EdWLubfMP2MP+iYJuQPw83hj+Y2Dvhtdz4fplhf9OM\n",
       "ApH2JMV2KZ+5JRTzr0tnfic/+oPTg8TFtsaphFu9KsVXgeYe3/x7jtCbBqCuHLgFK1/Eo7OV2I2N\n",
       "5x1zr/l2fZw3A74Uim6FOYoYaWc4wPlDkBJn2o9WDiXOLIsw422O4uvcLf1kMSRiBF4HqcCdH0A+\n",
       "IdEmmka7MT0eI7IBJENhywAAABIBn7VqQr8AAfxlUVg+4AMNBCAAAAAVQZu6SahBbJlMCHf//qmW\n",
       "AAADAPCBAAAAFUGf2EUVLC//AAF+iMVvjyklBfyGqQAAAA8Bn/d0Qr8AAfvgUSw1npgAAAAPAZ/5\n",
       "akK/AAH8ZVFYPZ6ZAAAAFUGb/kmoQWyZTAh3//6plgAAAwDwgAAAABVBnhxFFSwv/wABfojFb48p\n",
       "JQX8hqkAAAAPAZ47dEK/AAH74FEsNZ6ZAAAADwGePWpCvwAB/GVRWD2emAAAABVBmiJJqEFsmUwI\n",
       "d//+qZYAAAMA8IAAAAAVQZ5ARRUsL/8AAX6IxW+PKSUF/IapAAAADwGef3RCvwAB++BRLDWemAAA\n",
       "AA8BnmFqQr8AAfxlUVg9npkAAAAVQZpmSahBbJlMCHf//qmWAAADAPCAAAAAFUGehEUVLC//AAF+\n",
       "iMVvjyklBfyGqQAAAA8BnqN0Qr8AAfvgUSw1npkAAAAPAZ6lakK/AAH8ZVFYPZ6ZAAAAFUGaqkmo\n",
       "QWyZTAh3//6plgAAAwDwgQAAABVBnshFFSwv/wABfojFb48pJQX8hqgAAAAPAZ7ndEK/AAH74FEs\n",
       "NZ6YAAAADwGe6WpCvwAB/GVRWD2emQAAABVBmu5JqEFsmUwId//+qZYAAAMA8IAAAAAVQZ8MRRUs\n",
       "L/8AAX6IxW+PKSUF/IaoAAAADwGfK3RCvwAB++BRLDWemQAAAA8Bny1qQr8AAfxlUVg9npkAAAAV\n",
       "QZsySahBbJlMCHf//qmWAAADAPCBAAAAFUGfUEUVLC//AAF+iMVvjyklBfyGqAAAAA8Bn290Qr8A\n",
       "AfvgUSw1npgAAAAPAZ9xakK/AAH8ZVFYPZ6ZAAAAFUGbdkmoQWyZTAh3//6plgAAAwDwgAAAABVB\n",
       "n5RFFSwv/wABfojFb48pJQX8hqgAAAAPAZ+zdEK/AAH74FEsNZ6ZAAAADwGftWpCvwAB/GVRWD2e\n",
       "mAAAABVBm7pJqEFsmUwId//+qZYAAAMA8IEAAAAVQZ/YRRUsL/8AAX6IxW+PKSUF/IapAAAADwGf\n",
       "93RCvwAB++BRLDWemAAAAA8Bn/lqQr8AAfxlUVg9npkAAAAVQZv+SahBbJlMCHf//qmWAAADAPCA\n",
       "AAAAFUGeHEUVLC//AAF+iMVvjyklBfyGqQAAAA8Bnjt0Qr8AAfvgUSw1npkAAAAPAZ49akK/AAH8\n",
       "ZVFYPZ6YAAAAFUGaIkmoQWyZTAh3//6plgAAAwDwgAAAABVBnkBFFSwv/wABfojFb48pJQX8hqkA\n",
       "AAAPAZ5/dEK/AAH74FEsNZ6YAAAADwGeYWpCvwAB/GVRWD2emQAAABVBmmZJqEFsmUwId//+qZYA\n",
       "AAMA8IAAAAAVQZ6ERRUsL/8AAX6IxW+PKSUF/IapAAAADwGeo3RCvwAB++BRLDWemQAAAA8BnqVq\n",
       "Qr8AAfxlUVg9npkAAAAVQZqqSahBbJlMCHf//qmWAAADAPCBAAAAFUGeyEUVLC//AAF+iMVvjykl\n",
       "BfyGqAAAAA8Bnud0Qr8AAfvgUSw1npgAAAAPAZ7pakK/AAH8ZVFYPZ6ZAAAAFUGa7kmoQWyZTAh3\n",
       "//6plgAAAwDwgAAAABVBnwxFFSwv/wABfojFb48pJQX8hqgAAAAPAZ8rdEK/AAH74FEsNZ6ZAAAA\n",
       "DwGfLWpCvwAB/GVRWD2emQAAABVBmzJJqEFsmUwId//+qZYAAAMA8IEAAAAVQZ9QRRUsL/8AAX6I\n",
       "xW+PKSUF/IaoAAAADwGfb3RCvwAB++BRLDWemAAAAA8Bn3FqQr8AAfxlUVg9npkAAAAVQZt2SahB\n",
       "bJlMCHf//qmWAAADAPCAAAAAFUGflEUVLC//AAF+iMVvjyklBfyGqAAAAA8Bn7N0Qr8AAfvgUSw1\n",
       "npkAAAAPAZ+1akK/AAH8ZVFYPZ6YAAAAFEGbukmoQWyZTAhv//6nhAAAAwHdAAAAFUGf2EUVLC//\n",
       "AAF+iMVvjyklBfyGqQAAAA8Bn/d0Qr8AAfvgUSw1npgAAAAPAZ/5akK/AAH8ZVFYPZ6ZAAAAFEGb\n",
       "/kmoQWyZTAhv//6nhAAAAwHdAAAAFUGeHEUVLC//AAF+iMVvjyklBfyGqQAAAA8Bnjt0Qr8AAfvg\n",
       "USw1npkAAAAPAZ49akK/AAH8ZVFYPZ6YAAAAE0GaIkmoQWyZTAhf//6MsAAAB1QAAAAVQZ5ARRUs\n",
       "L/8AAX6IxW+PKSUF/IapAAAADwGef3RCvwAB++BRLDWemAAAAA8BnmFqQr8AAfxlUVg9npkAAAAT\n",
       "QZpjSahBbJlMCFf//jhAAAAccAAAB85tb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAPoAAB\n",
       "AAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAACAAAG+HRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAA\n",
       "AAAPoAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAB\n",
       "sAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAD6AAAAQAAAEAAAAABnBtZGlhAAAAIG1k\n",
       "aGQAAAAAAAAAAAAAAAAAADIAAADIAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAA\n",
       "AFZpZGVvSGFuZGxlcgAAAAYbbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJl\n",
       "ZgAAAAAAAAABAAAADHVybCAAAAABAAAF23N0YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2YzEAAAAA\n",
       "AAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAEAAADAMg8WLZY\n",
       "AQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAABk\n",
       "AAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAADIGN0dHMAAAAAAAAAYgAAAAEAAAQAAAAAAQAACAAA\n",
       "AAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAA\n",
       "AAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAA\n",
       "AQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAAB\n",
       "AAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEA\n",
       "AAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAA\n",
       "CgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAAC\n",
       "AAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAA\n",
       "AAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAA\n",
       "AAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAA\n",
       "AAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAA\n",
       "AQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAAB\n",
       "AAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEA\n",
       "AAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAA\n",
       "BAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAGQAAAABAAAB\n",
       "pHN0c3oAAAAAAAAAAAAAAGQAAAZGAAAB9wAAAXgAAADDAAAAuQAAAPwAAACPAAAA8gAAARgAAADI\n",
       "AAABrAAAAOYAAADEAAAA/QAAAKsAAAAoAAAAxwAAAEUAAACTAAAAGQAAAFUAAAC9AAAAFgAAABkA\n",
       "AAAZAAAAEwAAABMAAAAZAAAAGQAAABMAAAATAAAAGQAAABkAAAATAAAAEwAAABkAAAAZAAAAEwAA\n",
       "ABMAAAAZAAAAGQAAABMAAAATAAAAGQAAABkAAAATAAAAEwAAABkAAAAZAAAAEwAAABMAAAAZAAAA\n",
       "GQAAABMAAAATAAAAGQAAABkAAAATAAAAEwAAABkAAAAZAAAAEwAAABMAAAAZAAAAGQAAABMAAAAT\n",
       "AAAAGQAAABkAAAATAAAAEwAAABkAAAAZAAAAEwAAABMAAAAZAAAAGQAAABMAAAATAAAAGQAAABkA\n",
       "AAATAAAAEwAAABkAAAAZAAAAEwAAABMAAAAYAAAAGQAAABMAAAATAAAAGAAAABkAAAATAAAAEwAA\n",
       "ABcAAAAZAAAAEwAAABMAAAAXAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAA\n",
       "AAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0\n",
       "YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC1ElEQVR4nO3YIQ4CQRAAQZYgzvBgXsCDMbi5D2xw5FpUyVkzpjPJrpm5AT33qxcA9sQJUeKEKHFClDgh6vHr8Xm8feXCn32+r7Wbu5wQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQtWbm6h2ADZcTosQJUeKEKHFClDghSpwQdQJBKAvJnSOqAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(event_tensor[:,0,0].size())\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# anim = splt.animator(event_tensor[:,0,1], fig, ax)\n",
    "event_tensor, target = next(iter(train_loader))\n",
    "\n",
    "plt.figure(facecolor=\"w\")\n",
    "plt.subplot(1,2,1)\n",
    "spike_data_sample = spike_data[:,0,0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "anim = splt.animator(spike_data_sample, fig, ax)\n",
    "\n",
    "HTML(anim.to_html5_video())\n",
    "# plt.imshow(spike_data[:,0,0].mean(axis=0).reshape((34,-1)).cpu(), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae5d4b-2bb3-4191-9f96-04b3c6ba4c41",
   "metadata": {
    "id": "61ae5d4b-2bb3-4191-9f96-04b3c6ba4c41"
   },
   "source": [
    "## 2.1 Defining our network\n",
    "We will use snnTorch + PyTorch to construct a CSNN, just as in the previous tutorial. The convolutional network architecture to be used is: 12C5-MP2-32C5-MP2-800FC10\n",
    "\n",
    "- 12C5 is a 5$\\times$5 convolutional kernel with 12 filters\n",
    "- MP2 is a 2$\\times$2 max-pooling function\n",
    "- 800FC10 is a fully-connected layer that maps 800 neurons to 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "HpKDIkRKUIAB",
   "metadata": {
    "id": "HpKDIkRKUIAB"
   },
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import utils\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "107cb645-0227-4290-9e1b-25d6ae7eac87",
   "metadata": {
    "id": "107cb645-0227-4290-9e1b-25d6ae7eac87"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Conv2d(1, 12, 5), #12x32.32\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(12, 32, 5),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(32*5*5, 10),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "zPFvlqOGi_uW",
   "metadata": {
    "id": "zPFvlqOGi_uW"
   },
   "outputs": [],
   "source": [
    "# this time, we won't return membrane as we don't need it \n",
    "\n",
    "def forward_pass(net, data):  \n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(data.size(0)):  # data.size(0) = number of time steps\n",
    "      spk_out, mem_out = net(data[step])\n",
    "      spk_rec.append(spk_out)\n",
    "  \n",
    "  return torch.stack(spk_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23569dfc-e4a7-490f-8a68-c9ade5e03028",
   "metadata": {
    "id": "23569dfc-e4a7-490f-8a68-c9ade5e03028"
   },
   "source": [
    "## 2.2 Training\n",
    "\n",
    "In the previous tutorial, Cross Entropy Loss was applied to the total spike count to maximize the number of spikes from the correct class.\n",
    "\n",
    "Another option from the `snn.functional` module is to specify the target number of spikes from correct and incorrect classes. The approach below uses the *Mean Square Error Spike Count Loss*, which aims to elicit spikes from the correct class 80\\% of the time, and 20\\% of the time from incorrect classes. Encouraging incorrect neurons to fire could be motivated to avoid dead neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VocYbtD7Vwp7",
   "metadata": {
    "id": "VocYbtD7Vwp7"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss()\n",
    "# loss_fn = SF.mse_temporal_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7xkKLsqnmzcw",
   "metadata": {
    "id": "7xkKLsqnmzcw"
   },
   "source": [
    "Training neuromorphic data is expensive as it requires sequentially iterating through many time steps (approximately 300 time steps in the N-MNIST dataset). The following simulation will take some time, so we will just stick to training across 50 iterations (which is roughly 1/10th of a full epoch). Feel free to change `num_iters` if you have more time to kill. As we are printing results at each iteration, the results will be quite noisy and will also take some time before we start to see any sort of improvement.\n",
    "\n",
    "In our own experiments, it took about 20 iterations before we saw any improvement, and after 50 iterations, managed to crack ~60% accuracy. \n",
    "\n",
    "> Warning: the following simulation will take a while. Go make yourself a coffee, or ten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "R4GbPSdTUcUR",
   "metadata": {
    "id": "R4GbPSdTUcUR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0 \n",
      "Train Loss: 10.00\n",
      "Accuracy: 7.81%\n",
      "\n",
      "Epoch 0, Iteration 1 \n",
      "Train Loss: 10.00\n",
      "Accuracy: 7.03%\n",
      "\n",
      "Epoch 0, Iteration 2 \n",
      "Train Loss: 10.00\n",
      "Accuracy: 9.38%\n",
      "\n",
      "Epoch 0, Iteration 3 \n",
      "Train Loss: 9.95\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 4 \n",
      "Train Loss: 9.82\n",
      "Accuracy: 14.06%\n",
      "\n",
      "Epoch 0, Iteration 5 \n",
      "Train Loss: 9.59\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 6 \n",
      "Train Loss: 9.26\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 7 \n",
      "Train Loss: 9.00\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 8 \n",
      "Train Loss: 9.14\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 9 \n",
      "Train Loss: 9.21\n",
      "Accuracy: 17.97%\n",
      "\n",
      "Epoch 0, Iteration 10 \n",
      "Train Loss: 9.03\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 11 \n",
      "Train Loss: 8.88\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 12 \n",
      "Train Loss: 8.76\n",
      "Accuracy: 17.19%\n",
      "\n",
      "Epoch 0, Iteration 13 \n",
      "Train Loss: 8.90\n",
      "Accuracy: 22.66%\n",
      "\n",
      "Epoch 0, Iteration 14 \n",
      "Train Loss: 8.87\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 15 \n",
      "Train Loss: 8.76\n",
      "Accuracy: 25.78%\n",
      "\n",
      "Epoch 0, Iteration 16 \n",
      "Train Loss: 8.73\n",
      "Accuracy: 21.09%\n",
      "\n",
      "Epoch 0, Iteration 17 \n",
      "Train Loss: 8.60\n",
      "Accuracy: 24.22%\n",
      "\n",
      "Epoch 0, Iteration 18 \n",
      "Train Loss: 8.45\n",
      "Accuracy: 40.62%\n",
      "\n",
      "Epoch 0, Iteration 19 \n",
      "Train Loss: 8.41\n",
      "Accuracy: 37.50%\n",
      "\n",
      "Epoch 0, Iteration 20 \n",
      "Train Loss: 8.48\n",
      "Accuracy: 40.62%\n",
      "\n",
      "Epoch 0, Iteration 21 \n",
      "Train Loss: 8.35\n",
      "Accuracy: 39.06%\n",
      "\n",
      "Epoch 0, Iteration 22 \n",
      "Train Loss: 8.30\n",
      "Accuracy: 46.88%\n",
      "\n",
      "Epoch 0, Iteration 23 \n",
      "Train Loss: 8.17\n",
      "Accuracy: 47.66%\n",
      "\n",
      "Epoch 0, Iteration 24 \n",
      "Train Loss: 8.02\n",
      "Accuracy: 53.91%\n",
      "\n",
      "Epoch 0, Iteration 25 \n",
      "Train Loss: 8.10\n",
      "Accuracy: 51.56%\n",
      "\n",
      "Epoch 0, Iteration 26 \n",
      "Train Loss: 7.97\n",
      "Accuracy: 47.66%\n",
      "\n",
      "Epoch 0, Iteration 27 \n",
      "Train Loss: 7.82\n",
      "Accuracy: 53.91%\n",
      "\n",
      "Epoch 0, Iteration 28 \n",
      "Train Loss: 7.86\n",
      "Accuracy: 46.88%\n",
      "\n",
      "Epoch 0, Iteration 29 \n",
      "Train Loss: 7.63\n",
      "Accuracy: 54.69%\n",
      "\n",
      "Epoch 0, Iteration 30 \n",
      "Train Loss: 7.61\n",
      "Accuracy: 57.81%\n",
      "\n",
      "Epoch 0, Iteration 31 \n",
      "Train Loss: 7.71\n",
      "Accuracy: 52.34%\n",
      "\n",
      "Epoch 0, Iteration 32 \n",
      "Train Loss: 7.44\n",
      "Accuracy: 56.25%\n",
      "\n",
      "Epoch 0, Iteration 33 \n",
      "Train Loss: 7.53\n",
      "Accuracy: 53.91%\n",
      "\n",
      "Epoch 0, Iteration 34 \n",
      "Train Loss: 7.44\n",
      "Accuracy: 59.38%\n",
      "\n",
      "Epoch 0, Iteration 35 \n",
      "Train Loss: 7.58\n",
      "Accuracy: 52.34%\n",
      "\n",
      "Epoch 0, Iteration 36 \n",
      "Train Loss: 7.43\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 0, Iteration 37 \n",
      "Train Loss: 7.08\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 0, Iteration 38 \n",
      "Train Loss: 7.02\n",
      "Accuracy: 74.22%\n",
      "\n",
      "Epoch 0, Iteration 39 \n",
      "Train Loss: 7.12\n",
      "Accuracy: 64.84%\n",
      "\n",
      "Epoch 0, Iteration 40 \n",
      "Train Loss: 7.23\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 0, Iteration 41 \n",
      "Train Loss: 7.22\n",
      "Accuracy: 59.38%\n",
      "\n",
      "Epoch 0, Iteration 42 \n",
      "Train Loss: 6.96\n",
      "Accuracy: 60.94%\n",
      "\n",
      "Epoch 0, Iteration 43 \n",
      "Train Loss: 7.41\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Epoch 0, Iteration 44 \n",
      "Train Loss: 7.20\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 0, Iteration 45 \n",
      "Train Loss: 6.89\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 0, Iteration 46 \n",
      "Train Loss: 7.00\n",
      "Accuracy: 67.97%\n",
      "\n",
      "Epoch 0, Iteration 47 \n",
      "Train Loss: 7.51\n",
      "Accuracy: 54.69%\n",
      "\n",
      "Epoch 0, Iteration 48 \n",
      "Train Loss: 7.13\n",
      "Accuracy: 57.81%\n",
      "\n",
      "Epoch 0, Iteration 49 \n",
      "Train Loss: 7.44\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Epoch 0, Iteration 50 \n",
      "Train Loss: 7.12\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 1, Iteration 0 \n",
      "Train Loss: 7.12\n",
      "Accuracy: 61.72%\n",
      "\n",
      "Epoch 1, Iteration 1 \n",
      "Train Loss: 7.24\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 1, Iteration 2 \n",
      "Train Loss: 7.18\n",
      "Accuracy: 60.94%\n",
      "\n",
      "Epoch 1, Iteration 3 \n",
      "Train Loss: 7.20\n",
      "Accuracy: 58.59%\n",
      "\n",
      "Epoch 1, Iteration 4 \n",
      "Train Loss: 6.89\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 1, Iteration 5 \n",
      "Train Loss: 7.32\n",
      "Accuracy: 58.59%\n",
      "\n",
      "Epoch 1, Iteration 6 \n",
      "Train Loss: 7.00\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 1, Iteration 7 \n",
      "Train Loss: 7.07\n",
      "Accuracy: 64.84%\n",
      "\n",
      "Epoch 1, Iteration 8 \n",
      "Train Loss: 7.06\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 1, Iteration 9 \n",
      "Train Loss: 7.21\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 1, Iteration 10 \n",
      "Train Loss: 6.92\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 1, Iteration 11 \n",
      "Train Loss: 6.81\n",
      "Accuracy: 66.41%\n",
      "\n",
      "Epoch 1, Iteration 12 \n",
      "Train Loss: 6.99\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 1, Iteration 13 \n",
      "Train Loss: 6.86\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 1, Iteration 14 \n",
      "Train Loss: 6.84\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 1, Iteration 15 \n",
      "Train Loss: 7.17\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 1, Iteration 16 \n",
      "Train Loss: 6.70\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 1, Iteration 17 \n",
      "Train Loss: 6.88\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 1, Iteration 18 \n",
      "Train Loss: 7.13\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 1, Iteration 19 \n",
      "Train Loss: 6.62\n",
      "Accuracy: 77.34%\n",
      "\n",
      "Epoch 1, Iteration 20 \n",
      "Train Loss: 6.50\n",
      "Accuracy: 78.12%\n",
      "\n",
      "Epoch 1, Iteration 21 \n",
      "Train Loss: 6.61\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 1, Iteration 22 \n",
      "Train Loss: 6.62\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 1, Iteration 23 \n",
      "Train Loss: 6.87\n",
      "Accuracy: 71.09%\n",
      "\n",
      "Epoch 1, Iteration 24 \n",
      "Train Loss: 6.46\n",
      "Accuracy: 79.69%\n",
      "\n",
      "Epoch 1, Iteration 25 \n",
      "Train Loss: 6.69\n",
      "Accuracy: 67.97%\n",
      "\n",
      "Epoch 1, Iteration 26 \n",
      "Train Loss: 6.84\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 1, Iteration 27 \n",
      "Train Loss: 6.69\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 1, Iteration 28 \n",
      "Train Loss: 6.82\n",
      "Accuracy: 71.09%\n",
      "\n",
      "Epoch 1, Iteration 29 \n",
      "Train Loss: 6.69\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 1, Iteration 30 \n",
      "Train Loss: 6.52\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 1, Iteration 31 \n",
      "Train Loss: 6.54\n",
      "Accuracy: 75.78%\n",
      "\n",
      "Epoch 1, Iteration 32 \n",
      "Train Loss: 6.70\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 1, Iteration 33 \n",
      "Train Loss: 6.56\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 1, Iteration 34 \n",
      "Train Loss: 6.73\n",
      "Accuracy: 70.31%\n",
      "\n",
      "Epoch 1, Iteration 35 \n",
      "Train Loss: 6.81\n",
      "Accuracy: 64.84%\n",
      "\n",
      "Epoch 1, Iteration 36 \n",
      "Train Loss: 6.66\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 1, Iteration 37 \n",
      "Train Loss: 7.03\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 1, Iteration 38 \n",
      "Train Loss: 6.88\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 1, Iteration 39 \n",
      "Train Loss: 6.59\n",
      "Accuracy: 81.25%\n",
      "\n",
      "Epoch 1, Iteration 40 \n",
      "Train Loss: 6.75\n",
      "Accuracy: 75.00%\n",
      "\n",
      "Epoch 1, Iteration 41 \n",
      "Train Loss: 6.76\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 1, Iteration 42 \n",
      "Train Loss: 6.92\n",
      "Accuracy: 62.50%\n",
      "\n",
      "Epoch 1, Iteration 43 \n",
      "Train Loss: 6.95\n",
      "Accuracy: 57.03%\n",
      "\n",
      "Epoch 1, Iteration 44 \n",
      "Train Loss: 6.62\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 1, Iteration 45 \n",
      "Train Loss: 6.82\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 1, Iteration 46 \n",
      "Train Loss: 6.40\n",
      "Accuracy: 77.34%\n",
      "\n",
      "Epoch 1, Iteration 47 \n",
      "Train Loss: 6.57\n",
      "Accuracy: 75.00%\n",
      "\n",
      "Epoch 1, Iteration 48 \n",
      "Train Loss: 6.51\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 1, Iteration 49 \n",
      "Train Loss: 6.71\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 1, Iteration 50 \n",
      "Train Loss: 6.51\n",
      "Accuracy: 75.00%\n",
      "\n",
      "Epoch 2, Iteration 0 \n",
      "Train Loss: 6.56\n",
      "Accuracy: 71.09%\n",
      "\n",
      "Epoch 2, Iteration 1 \n",
      "Train Loss: 6.72\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 2, Iteration 2 \n",
      "Train Loss: 6.92\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 2, Iteration 3 \n",
      "Train Loss: 6.65\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 2, Iteration 4 \n",
      "Train Loss: 6.54\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 2, Iteration 5 \n",
      "Train Loss: 6.60\n",
      "Accuracy: 78.91%\n",
      "\n",
      "Epoch 2, Iteration 6 \n",
      "Train Loss: 6.54\n",
      "Accuracy: 75.78%\n",
      "\n",
      "Epoch 2, Iteration 7 \n",
      "Train Loss: 6.64\n",
      "Accuracy: 67.97%\n",
      "\n",
      "Epoch 2, Iteration 8 \n",
      "Train Loss: 6.61\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 2, Iteration 9 \n",
      "Train Loss: 6.71\n",
      "Accuracy: 65.62%\n",
      "\n",
      "Epoch 2, Iteration 10 \n",
      "Train Loss: 6.68\n",
      "Accuracy: 64.84%\n",
      "\n",
      "Epoch 2, Iteration 11 \n",
      "Train Loss: 6.71\n",
      "Accuracy: 71.09%\n",
      "\n",
      "Epoch 2, Iteration 12 \n",
      "Train Loss: 6.43\n",
      "Accuracy: 75.78%\n",
      "\n",
      "Epoch 2, Iteration 13 \n",
      "Train Loss: 6.61\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 2, Iteration 14 \n",
      "Train Loss: 6.74\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 2, Iteration 15 \n",
      "Train Loss: 6.60\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 2, Iteration 16 \n",
      "Train Loss: 6.51\n",
      "Accuracy: 75.78%\n",
      "\n",
      "Epoch 2, Iteration 17 \n",
      "Train Loss: 6.91\n",
      "Accuracy: 66.41%\n",
      "\n",
      "Epoch 2, Iteration 18 \n",
      "Train Loss: 6.72\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 2, Iteration 19 \n",
      "Train Loss: 6.46\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 2, Iteration 20 \n",
      "Train Loss: 6.70\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 2, Iteration 21 \n",
      "Train Loss: 6.56\n",
      "Accuracy: 70.31%\n",
      "\n",
      "Epoch 2, Iteration 22 \n",
      "Train Loss: 6.42\n",
      "Accuracy: 74.22%\n",
      "\n",
      "Epoch 2, Iteration 23 \n",
      "Train Loss: 6.51\n",
      "Accuracy: 74.22%\n",
      "\n",
      "Epoch 2, Iteration 24 \n",
      "Train Loss: 6.53\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 2, Iteration 25 \n",
      "Train Loss: 6.44\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 2, Iteration 26 \n",
      "Train Loss: 6.39\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 2, Iteration 27 \n",
      "Train Loss: 6.42\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 2, Iteration 28 \n",
      "Train Loss: 6.50\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 2, Iteration 29 \n",
      "Train Loss: 6.70\n",
      "Accuracy: 66.41%\n",
      "\n",
      "Epoch 2, Iteration 30 \n",
      "Train Loss: 6.58\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Epoch 2, Iteration 31 \n",
      "Train Loss: 6.56\n",
      "Accuracy: 72.66%\n",
      "\n",
      "Epoch 2, Iteration 32 \n",
      "Train Loss: 6.67\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 2, Iteration 33 \n",
      "Train Loss: 6.31\n",
      "Accuracy: 81.25%\n",
      "\n",
      "Epoch 2, Iteration 34 \n",
      "Train Loss: 6.61\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Epoch 2, Iteration 35 \n",
      "Train Loss: 6.36\n",
      "Accuracy: 79.69%\n",
      "\n",
      "Epoch 2, Iteration 36 \n",
      "Train Loss: 6.70\n",
      "Accuracy: 67.19%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_iters = 50\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "#         data = spikegen.rate(data, num_steps=num_steps)\n",
    "        data = spikegen.latency(data, num_steps=num_steps, tau=5, threshold=0.8, clip=True, normalize=True, linear=True)\n",
    "\n",
    "\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    " \n",
    "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
    "\n",
    "        acc = SF.accuracy_rate(spk_rec, targets) \n",
    "        acc_hist.append(acc)\n",
    "        print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "#         This will end train÷ing after 50 iterations by default\n",
    "        if i == num_iters:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Loss\n",
    "fig = plt.figure(facecolor=\"w\")\n",
    "plt.plot(acc_hist)\n",
    "plt.title(\"Train Set Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YVjUzNcX0wld",
   "metadata": {
    "id": "YVjUzNcX0wld"
   },
   "source": [
    "# 3. Results\n",
    "## 3.1 Plot Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yp2aTX2_1zFG",
   "metadata": {
    "id": "yp2aTX2_1zFG"
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "    \n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "        \n",
    "      data = spikegen.rate(data, num_steps=num_steps)\n",
    "      spk_rec = forward_pass(net, data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net)\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf953d1a",
   "metadata": {},
   "source": [
    "## saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1gb1wCQb2bMd",
   "metadata": {
    "id": "1gb1wCQb2bMd"
   },
   "source": [
    "## 3.2 Spike Counter\n",
    "\n",
    "Run a forward pass on a batch of data to obtain spike recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qLAfvj9D2AYd",
   "metadata": {
    "id": "qLAfvj9D2AYd"
   },
   "outputs": [],
   "source": [
    "spk_rec = forward_pass(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQnj40YC2hUV",
   "metadata": {
    "id": "VQnj40YC2hUV"
   },
   "source": [
    "Changing `idx` allows you to index into various samples from the simulated minibatch. Use `splt.spike_count` to explore the spiking behaviour of a few different samples. Generating the following animation will take some time.\n",
    "\n",
    "> Note: if you are running the notebook locally on your desktop, please uncomment the line below and modify the path to your ffmpeg.exe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oTKhuyk22M57",
   "metadata": {
    "id": "oTKhuyk22M57"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "idx = 1\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
    "labels=['0', '1', '2', '3', '4', '5', '6', '7', '8','9']\n",
    "print(f\"The target label is: {targets[idx]}\")\n",
    "\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
    "\n",
    "#  Plot spike count histogram\n",
    "anim = splt.spike_count(spk_rec[:, idx].detach().cpu(), fig, ax, labels=labels, \n",
    "                        animate=True, interpolate=1)\n",
    "\n",
    "HTML(anim.to_html5_video())\n",
    "# anim.save(\"spike_bar.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-iSGTq0Q3Lcm",
   "metadata": {
    "id": "-iSGTq0Q3Lcm"
   },
   "source": [
    "# Conclusion\n",
    "If you made it this far, then congratulations - you have the patience of a monk. You should now also understand how to load neuromorphic datasets using Tonic and then train a network using snnTorch. [In the next tutorial](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), we will learn more advanced techniques, such as introducing long-term temporal dynamics into our SNNs.\n",
    "\n",
    "If you like this project, please consider starring ⭐ the repo on GitHub as it is the easiest and best way to support it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h-K_DUnsMKnv",
   "metadata": {
    "id": "h-K_DUnsMKnv"
   },
   "source": [
    "# Additional Resources\n",
    "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)\n",
    "* [The Tonic GitHub project can be found here.](https://github.com/neuromorphs/tonic)\n",
    "* The N-MNIST Dataset was originally published in the following paper: [Orchard, G.; Cohen, G.; Jayawant, A.; and Thakor, N.  “Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades\", Frontiers in Neuroscience, vol.9, no.437, Oct. 2015.](https://www.frontiersin.org/articles/10.3389/fnins.2015.00437/full) \n",
    "* For further information about how N-MNIST was created, please refer to [Garrick Orchard's website here.](https://www.garrickorchard.com/datasets/n-mnist)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Copy of tutorial_5_neuromorphic_datasets.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
